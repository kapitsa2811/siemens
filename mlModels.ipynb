{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    this code performs anomalies detection\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    this code performs anomalies detection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret\n",
    "import pandas as pd\n",
    "import os\n",
    "import  matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pycaret.anomaly import *\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    reads a file from which None rows are removed\n",
    "'''\n",
    "\n",
    "filePath=\".//data//\"\n",
    "fileName=\"data_sample.csv\"\n",
    "modelPath=\".//model//\"\n",
    "resultPath=\".//results//\"\n",
    "\n",
    "'''\n",
    "    If below variable is one then it trains a model from scratch\n",
    "    otherwise it just do prediction from already trained model\n",
    "'''\n",
    "trainModels=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def readData():\n",
    "        df1=pd.read_csv(filePath+fileName)\n",
    "        print(\"\\n\\t shape:\",df1.shape)\n",
    "\n",
    "        return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t shape: (106749, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeUTC</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-19 14:40:00</td>\n",
       "      <td>4.94</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-19 14:50:00</td>\n",
       "      <td>4.78</td>\n",
       "      <td>139.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-19 15:00:00</td>\n",
       "      <td>4.88</td>\n",
       "      <td>140.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-19 15:10:00</td>\n",
       "      <td>4.81</td>\n",
       "      <td>139.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-19 15:20:00</td>\n",
       "      <td>4.76</td>\n",
       "      <td>137.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timeUTC  wind_speed  wind_direction\n",
       "0  2014-12-19 14:40:00        4.94           138.0\n",
       "1  2014-12-19 14:50:00        4.78           139.2\n",
       "2  2014-12-19 15:00:00        4.88           140.6\n",
       "3  2014-12-19 15:10:00        4.81           139.4\n",
       "4  2014-12-19 15:20:00        4.76           137.3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=readData()\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6687ecae_3de2_11eb_8685_6045cba87229row2_col1,#T_6687ecae_3de2_11eb_8685_6045cba87229row21_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_6687ecae_3de2_11eb_8685_6045cba87229\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row0_col1\" class=\"data row0 col1\" >124</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row1_col0\" class=\"data row1 col0\" >Original Data</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row1_col1\" class=\"data row1 col1\" >(101411, 3)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row2_col0\" class=\"data row2 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row3_col0\" class=\"data row3 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row4_col0\" class=\"data row4 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row5_col0\" class=\"data row5 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row6_col0\" class=\"data row6 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row7_col0\" class=\"data row7 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row8_col0\" class=\"data row8 col0\" >Transformed Data</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row8_col1\" class=\"data row8 col1\" >(101411, 2)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row9_col0\" class=\"data row9 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row9_col1\" class=\"data row9 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row10_col0\" class=\"data row10 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row10_col1\" class=\"data row10 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row11_col0\" class=\"data row11 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row12_col0\" class=\"data row12 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row12_col1\" class=\"data row12 col1\" >anomaly-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row13_col0\" class=\"data row13 col0\" >USI</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row13_col1\" class=\"data row13 col1\" >885c</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row14_col0\" class=\"data row14 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row14_col1\" class=\"data row14 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row15_col0\" class=\"data row15 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row16_col0\" class=\"data row16 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row16_col1\" class=\"data row16 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row17_col0\" class=\"data row17 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row17_col1\" class=\"data row17 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row18_col0\" class=\"data row18 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row18_col1\" class=\"data row18 col1\" >mode</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row19_col0\" class=\"data row19 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row19_col1\" class=\"data row19 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row20_col0\" class=\"data row20 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row20_col1\" class=\"data row20 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row21_col0\" class=\"data row21 col0\" >Normalize</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row21_col1\" class=\"data row21 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row22_col0\" class=\"data row22 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row22_col1\" class=\"data row22 col1\" >zscore</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row23_col0\" class=\"data row23 col0\" >Transformation</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row23_col1\" class=\"data row23 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row24_col0\" class=\"data row24 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row24_col1\" class=\"data row24 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row25_col0\" class=\"data row25 col0\" >PCA</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row26_col0\" class=\"data row26 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row27_col0\" class=\"data row27 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row28_col0\" class=\"data row28 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row28_col1\" class=\"data row28 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row29_col0\" class=\"data row29 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row30_col0\" class=\"data row30 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row31_col0\" class=\"data row31 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row32_col0\" class=\"data row32 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row32_col1\" class=\"data row32 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row33_col0\" class=\"data row33 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row33_col1\" class=\"data row33 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row34_col0\" class=\"data row34 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row35_col0\" class=\"data row35 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row36_col0\" class=\"data row36 col0\" >Clustering</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row37_col0\" class=\"data row37 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row37_col1\" class=\"data row37 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row38_col0\" class=\"data row38 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row38_col1\" class=\"data row38 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row39_col0\" class=\"data row39 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row39_col1\" class=\"data row39 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row40_col0\" class=\"data row40 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row41_col0\" class=\"data row41 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row42_col0\" class=\"data row42 col0\" >Group Features</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row43_col0\" class=\"data row43 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row43_col1\" class=\"data row43 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row44_col0\" class=\"data row44 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row44_col1\" class=\"data row44 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row45_col0\" class=\"data row45 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row46_col0\" class=\"data row46 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6687ecae_3de2_11eb_8685_6045cba87229level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row47_col0\" class=\"data row47 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_6687ecae_3de2_11eb_8685_6045cba87229row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fba58d522b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t 2.train data: 36\n"
     ]
    }
   ],
   "source": [
    "dAnomoly=defaultdict(int)\n",
    "train, test = train_test_split(df1, test_size=0.05, shuffle=False)\n",
    "print(\"\\n\\t 1.train data:\",len(train))\n",
    "print(\"\\n\\t test data:\",len(test))\n",
    "#iforest=createModel()  \n",
    "\n",
    "train = setup(train, normalize=True, ignore_features=['timeUTC'], session_id=124)  #\n",
    "print(\"\\n\\t 2.train data:\",len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t train data: 36\n",
      "\n",
      "\t test data: 5338\n"
     ]
    }
   ],
   "source": [
    "def count(temp,dAnomoly):\n",
    "    exceptionCount=0\n",
    "    #dAnomoly=defaultdict(int)\n",
    "    for indx, row in temp.iterrows():\n",
    "        \n",
    "        try:\n",
    "            if row[\"Anomaly\"]==1:\n",
    "                #print(\"\\n\\t row :\",row )\n",
    "                key=str([row[\"timeUTC\"],row[\"wind_speed\"],row[\"wind_direction\"]])\n",
    "                #row = tuple(row[\"timeUTC\"],row[\"wind_speed\"],row[\"wind_direction\"])\n",
    "                #print(\"\\n\\t key:\",key)\n",
    "                dAnomoly[key] += 1\n",
    "        except Exception as e:\n",
    "            exceptionCount+=1\n",
    "            #print(\"\\n\\t exception is:\",e)\n",
    "            \n",
    "    print(\"\\n\\t exceptionCount:\",exceptionCount)\n",
    "    \n",
    "    #print(\"\\n\\t number of rows:\",indx)\n",
    "    return dAnomoly\n",
    "\n",
    "#dAnomolyTrain=defaultdict(int)\n",
    "#dAnomolyTest=defaultdict(int)\n",
    "\n",
    "print(\"\\n\\t train data:\",len(train))\n",
    "print(\"\\n\\t test data:\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Succesfully Saved\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    train part isolation forest\n",
    "'''\n",
    "trainModels=1\n",
    "if trainModels==1:\n",
    "    print(\"\\n\\t 1.training model from scratch!!!\")\n",
    "    iforest = create_model('iforest')\n",
    "    save_model(iforest,modelPath+'iforest')\n",
    "\n",
    "elif os.path.isfile(modelPath+'iforest.pkl'):\n",
    "    '''\n",
    "        loads model if already present\n",
    "    '''\n",
    "    \n",
    "    print(\"\\n\\t 1.using pretrained model training model\")\n",
    "    saved_iforest = load_model(modelPath+'iforest')\n",
    "\n",
    "else:\n",
    "    print(\"\\n\\t model absent please set trainModels=1 to retrain\")\n",
    "\n",
    "'''\n",
    "    prediction part\n",
    "'''\n",
    "\n",
    "if trainModels==1:\n",
    "    \n",
    "    '''\n",
    "        prediction on train data\n",
    "    '''\n",
    "    outlier_results_iforest=assign_model(iforest)\n",
    "    outlier_results_iforest.to_csv(resultPath+\"outlier_results_iforest_train.csv\",index=False)\n",
    "\n",
    "    '''\n",
    "        prediction on test data\n",
    "    '''\n",
    "    unseen_predictions = predict_model(iforest, data=test)\n",
    "    #unseen_predictions.head()\n",
    "    #input(\"check\")\n",
    "    unseen_predictions.insert(0,\"timeUTC\",test[\"timeUTC\"],True)\n",
    "    unseen_predictions.to_csv(resultPath+\"outlier_results_iforest_test_predictions.csv\",index=False)\n",
    "else:\n",
    "    \n",
    "    outlier_results_iforest = assign_model(saved_iforest)#predict_model(saved_iforest, data=test)\n",
    "    outlier_results_iforest.to_csv(resultPath+\"outlier_results_iforest_train.csv\",index=False)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        prediction on test data\n",
    "    '''\n",
    "    unseen_predictions = predict_model(saved_iforest, data=test)\n",
    "    unseen_predictions.insert(0,\"timeUTC\",test[\"timeUTC\"],True)\n",
    "    #unseen_predictions.head()\n",
    "    unseen_predictions.to_csv(resultPath+\"outlier_results_iforest_test_predictions.csv\",index=False)\n",
    "    \n",
    "print(\"\\n\\t train prediction size:\",outlier_results_iforest.shape)\n",
    "print(\"\\n\\t test prediction size:\",unseen_predictions.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t exceptionCount: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5071"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dAnomolyTrain=defaultdict(int)\n",
    "\n",
    "\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "len(dAnomolyTrain.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t dict length: 590\n"
     ]
    }
   ],
   "source": [
    "#len(unseen_predictions)\n",
    "\n",
    "dAnomolyTest=defaultdict(int)\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "\n",
    "print(\"\\n\\t dict length:\",len(dAnomolyTest.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modeltrain(classifierName,trainModels):\n",
    "    '''\n",
    "        train part isolation forest\n",
    "    '''\n",
    "    #trainModels=1\n",
    "    if trainModels==1:\n",
    "        print(\"\\n\\t training model from scratch!!!:\",classifierName)\n",
    "        iforest = create_model(classifierName)\n",
    "        save_model(iforest,modelPath+classifierName)\n",
    "\n",
    "    elif os.path.isfile(modelPath+classifierName+'.pkl'):\n",
    "        '''\n",
    "            loads model if already present\n",
    "        '''\n",
    "\n",
    "        print(\"\\n\\t 1.using pretrained model training model\")\n",
    "        saved_iforest = load_model(modelPath+classifierName)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n\\t model absent please set trainModels=1 to retrain\")\n",
    "\n",
    "    '''\n",
    "        prediction part\n",
    "    '''\n",
    "\n",
    "    if trainModels==1:\n",
    "\n",
    "        '''\n",
    "            prediction on train data\n",
    "        '''\n",
    "        outlier_results_iforest=assign_model(iforest)\n",
    "        outlier_results_iforest.to_csv(resultPath+\"outlier_results_\"+classifierName+\"_train.csv\",index=False)\n",
    "\n",
    "        '''\n",
    "            prediction on test data\n",
    "        '''\n",
    "        unseen_predictions = predict_model(iforest, data=test)\n",
    "        #unseen_predictions.head()\n",
    "        #input(\"check\")\n",
    "        unseen_predictions.insert(0,\"timeUTC\",test[\"timeUTC\"],True)\n",
    "        unseen_predictions.to_csv(resultPath+\"outlier_results_\"+classifierName+\"_test_predictions.csv\",index=False)\n",
    "    else:\n",
    "\n",
    "        outlier_results_iforest = assign_model(saved_iforest)#predict_model(saved_iforest, data=test)\n",
    "        outlier_results_iforest.to_csv(resultPath+\"outlier_results_\"+classifierName+\"_train.csv\",index=False)\n",
    "\n",
    "\n",
    "        '''\n",
    "            prediction on test data\n",
    "        '''\n",
    "        unseen_predictions = predict_model(saved_iforest, data=test)\n",
    "        unseen_predictions.insert(0,\"timeUTC\",test[\"timeUTC\"],True)\n",
    "        #unseen_predictions.head()\n",
    "        unseen_predictions.to_csv(resultPath+\"outlier_results_\"+classifierName+\"_test_predictions.csv\",index=False)\n",
    "    \n",
    "    print(\"\\n\\t train prediction size:\",outlier_results_iforest.shape)\n",
    "    print(\"\\n\\t test prediction size:\",unseen_predictions.shape)\n",
    "    \n",
    "    return outlier_results_iforest,unseen_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 5071\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 590\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 7514\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 780\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 9321\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 909\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 9321\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 909\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 11630\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 931\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 14573\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 1118\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 15984\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 1274\n",
      "\n",
      "\t 1.using pretrained model training model\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "\t train prediction size: (101411, 5)\n",
      "\n",
      "\t test prediction size: (5338, 5)\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 1.dict length: 15991\n",
      "\n",
      "\t exceptionCount: 0\n",
      "\n",
      "\t 2.dict length: 1274\n"
     ]
    }
   ],
   "source": [
    "trainModels=0\n",
    "\n",
    "dAnomolyTrain=defaultdict(int)\n",
    "dAnomolyTest=defaultdict(int)\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('iforest',trainModels)    \n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('knn',trainModels)    \n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('cluster',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('abod',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('histogram',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('lof',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('pca',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "#######################################\n",
    "\n",
    "#######################################\n",
    "outlier_results_iforest,unseen_predictions=modeltrain('svm',trainModels)\n",
    "dAnomolyTrain=count(outlier_results_iforest,dAnomolyTrain)\n",
    "print(\"\\n\\t 1.dict length:\",len(dAnomolyTrain.keys()))\n",
    "dAnomolyTest=count(unseen_predictions,dAnomolyTest)\n",
    "print(\"\\n\\t 2.dict length:\",len(dAnomolyTest.keys()))\n",
    "\n",
    "\n",
    "dictFrame = pd.DataFrame.from_dict(dAnomolyTrain.items())\n",
    "#dictFrame.to_csv(resultPath+\"dAnomolyTrain.csv\")\n",
    "\n",
    "dictFrame = pd.DataFrame.from_dict(dAnomolyTest.items())\n",
    "#dictFrame.to_csv(resultPath+\"dAnomolyTest.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    test data\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    here I check how many time particular sample is counted by outlier classifie\n",
    "    New column named count is added to store that count\n",
    "'''\n",
    "\n",
    "#outlier_results_iforest,unseen_predictions\n",
    "\n",
    "def outlierVoting(df,d):\n",
    "    \n",
    "    df[\"vote\"]=0\n",
    "    \n",
    "    for indx,row in df.iterrows(): \n",
    "        \n",
    "        #print(\"\\n\\t row:\",row)\n",
    "        key=str([row[\"timeUTC\"],row[\"wind_speed\"],row[\"wind_direction\"]])\n",
    "        \n",
    "        if key in d.keys():\n",
    "            df.loc[indx,\"vote\"]=d[key]\n",
    "        else:\n",
    "            df.loc[indx,\"vote\"]=0\n",
    "        \n",
    "#         if indx>100:\n",
    "#             break\n",
    "    \n",
    "    return df\n",
    "    \n",
    "'''\n",
    "    training data\n",
    "'''\n",
    "df=outlierVoting(outlier_results_iforest,dAnomolyTrain)\n",
    "\n",
    "df.to_csv(resultPath+\"outlierVoting.csv\",index=False)\n",
    "\n",
    "'''\n",
    "    test data\n",
    "'''\n",
    "#outlierVoting(unseen_predictions,dAnomolyTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
